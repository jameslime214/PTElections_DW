import os
import pandas as pd


def iter_filepaths(directory: str):
    """
    Yields the full path for each file in the specified directory.
    
    Parameters:
        directory: The path to the directory.
        
    Yields:
        str: The full file path of each file in the directory.
    """
    for filename in os.listdir(directory):
        filepath = os.path.join(directory, filename)
        if os.path.isfile(filepath):
            yield filepath
    

def extract_dataframe_from_txt(file_path: str, *, _encoding: str = 'utf-8') -> pd.DataFrame:
    """
    Extract data from a text file into a pandas DataFrame without any cleaning.
    
    Parameters:
        file_path: Path to the input text file
        encoding: Character encoding to use when reading the file
        
    Returns:
        pandas.DataFrame: Raw data extracted from the text file
        
    Raises:
        ValueError: If the file is not a .txt file or if an error occurs during reading
    """
    ## Ensure the file has a .txt extension
    if os.path.splitext(file_path)[1].lower() != '.txt':
        raise ValueError("Unsupported file format. This function only processes .txt files.")

    try:
        ## Read the file as fixed-width format without header
        df = pd.read_fwf(file_path, encoding= _encoding, header= None)
        return df
    except Exception as e:
        raise ValueError(f"Error reading fixed-width file: {str(e)}")
    

def extract_dataframe_from_excel(file_path: str) -> pd.DataFrame:
    """
    Extract data from an Excel file into a pandas DataFrame.
    
    Parameters:
        file_path: Path to the input Excel file (.xls or .xlsx)
        
    Returns:
        pandas.DataFrame: Data extracted from the Excel file
        
    Raises:
        ValueError: If the file is not an Excel file or if an error occurs during reading
    """
    ## Ensure the file has an Excel extension
    ext = os.path.splitext(file_path)[1].lower()
    if ext not in ['.xls', '.xlsx', '.csv']:
        raise ValueError("Unsupported file format. This function only processes Excel files, including csv.")

    try:
        ## Read the Excel file
        if ext == '.csv':
            df = pd.read_csv(file_path)
        elif ext == '.xls':
            df = pd.read_excel(file_path, engine='xlrd')
        elif ext == '.xlsx':
            df = pd.read_excel(file_path, engine='openpyxl')
        return df
    except Exception as e:
        raise ValueError(f"Error reading Excel file: {str(e)}")
    

def save_dataframe_to_excel(df: pd.DataFrame, output_path: str, *, _replace: bool = False) -> None:
    """
    Save a DataFrame to an Excel file, with an option to overwrite an existing file.
    
    If _replace is False (default) and an Excel file already exists at the provided output_path,
    a new file name will be generated by appending an underscore and a counter to the base file name.
    If _replace is True, the file will be overwritten if it already exists.
    
    Parameters:
        df: DataFrame to save
        output_path: Full path where the Excel file will be saved
        _replace: Boolean flag indicating whether to overwrite an existing file (default: False)
        
    Returns:
        None
    """
    
    # Ensure the target directory exists
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # Only modify the output_path if _replace is False
    if not _replace:
        base, ext = os.path.splitext(output_path)
        counter = 1
        while os.path.exists(output_path):
            output_path = f"{base}_{counter}{ext}"
            counter += 1

    # Write the DataFrame to Excel (overwrites if _replace is True)
    try:
        with pd.ExcelWriter(output_path, engine='openpyxl', mode='w') as writer:
            df.to_excel(writer, index=False)
        saved_filename = os.path.basename(output_path)
        target_directory = os.path.dirname(output_path)
        print(f"Successfully saved {saved_filename} to {target_directory}")
    except Exception as e:
        raise ValueError(f"Error writing Excel file: {str(e)}")
    

def parse_FC_data_1(df: pd.DataFrame) -> pd.DataFrame:
    """
    Remove columns from a DataFrame where all values are either 0, '0', or null.
    
    This function is intended for cleaning the dataframes extracted from text files
    where some columns contain only zeros or null values and don't contribute 
    meaningful information.
    
    Parameters:
        df: Input DataFrame to clean.
        
    Returns:
        pandas.DataFrame: DataFrame with zero-only columns removed.
    """
    ## Create a copy to avoid modifying the original DataFrame
    cleaned_df = df.copy()
    
    ## List to store columns that should be kept
    columns_to_keep = []
    
    for col in cleaned_df.columns:
        ## Check if column contains only 0s (numeric), '0' (string), or null values
        is_all_zeros = cleaned_df[col].apply(
            lambda x: x == 0 or x == '0' or pd.isna(x)
        ).all()
        
        ## If not all zeros, keep the column
        if not is_all_zeros:
            columns_to_keep.append(col)
    
    ## Return DataFrame with only the columns to keep
    return cleaned_df[columns_to_keep]


def parse_FC_data_2(df: pd.DataFrame) -> pd.DataFrame:
    """
    Process a DataFrame containing municipal or parish data where the first column contains 
    combined numeric + text data (e.g. "123456Municipality Name").
    
    This function splits the first column into two parts:
      - A new leftmost column containing the numeric code.
      - The original first column is replaced with only the non-numeric (text) part.
    
    Parameters:
        df: Input DataFrame.
        
    Returns:
        pandas.DataFrame: Modified DataFrame with split first column.
    """
    ## Create a copy to avoid modifying the original DataFrame
    new_df = df.copy()
    
    ## Ensure values are treated as strings
    col0 = new_df[0].astype(str)

    ## Extract numeric part from the first column using a regex
    numeric_part = col0.str.extract(r'^(\d+)')[0].astype('int64')
    
    ## Extract text part from the first column (trim any whitespace)
    text_part = col0.str.extract(r'^\d+(.*)$')[0].str.strip()
    
    ## Create a new DataFrame with the extracted parts and all remaining columns
    result_df = pd.concat([numeric_part, text_part, new_df.iloc[:, 1:]], axis=1)
    
    ## Reset the column indeces
    result_df.columns = range(len(result_df.columns))
    
    return result_df


def parse_FC76_data(df):
    """
    Process the intermediate column (column index 2) in 76 files.
    
    For 76 files, the intermediate column is a string with a fixed pattern:
      - If there's no voting data, it appears as "500{spaces}0".
      - Otherwise, it starts with extraneous zeros, contains the important numeric value, and ends with a trailing '0'.
    
    This function extracts the numeric part and returns the column as an int64.
    """

    cleaned_df = df.copy()
    
    def process_value(val):
        # Convert value to string and strip surrounding whitespace.
        s = str(val).strip()
        # If no voting data, pattern starts with "500"
        if s.startswith("500"):
            return 5000
        else:
            # Remove trailing '0' if present.
            if s.endswith("0"):
                s = s[:-1]
            # Remove leading zeros.
            s = s.lstrip("0")
            try:
                return int(s) if s != "" else 0
            except Exception:
                return pd.NA

    cleaned_df[2] = cleaned_df[2].apply(process_value).astype("Int64")
    return cleaned_df


def create_column_mapping(_ext: str, _name: str, _df: pd.DataFrame) -> dict:
    """
    Create a dictionary mapping the DataFrame's column indices to new names based on file metadata.
    
    Parameters:
        _ext: The file extension. A mapping is only created if this is ".txt".
        _name: The base name of the file which determines naming for the first two columns.
        _df: The DataFrame to be processed.

    Returns:
        A dictionary where the keys are the original column indices and the values are the new column names.

    Naming rules:
        - Only applies when file_ext is ".txt".
        - If base_name ends with "c": first two columns correspond to municipality code and name.
        - If base_name ends with "f": first two columns correspond to parish code and name.
        - In all cases:
            Column 2 is named "num".
            Column 3-6 are total vote data.
        - For any remaining columns (from index 7 onward), assign (party acronym, vote count) pairs.
    """
    ## Only create a mapping for .txt files.
    if _ext.lower() != ".txt":
        return {}

    mapping = {}
    ## Determine names for the first two columns based on base_name.
    if _name.lower().endswith("c"):
        mapping[0] = "municipality_code"
        mapping[1] = "municipality_name"
    elif _name.lower().endswith("f"):
        mapping[0] = "parish_code"
        mapping[1] = "parish_name"
    else:
        ## Fallback names if base_name doesn't end with 'c' or 'f'
        mapping[0] = "code"
        mapping[1] = "name"

    ## Set fixed names for the next five columns.
    mapping[2] = "num"
    mapping[3] = "total_registered"
    mapping[4] = "total_votes"
    mapping[5] = "blank_votes"
    mapping[6] = "null_votes"

    ## For remaining columns starting at index 7, in pairs.
    ## Use the first non-null entry of each party acronym column as the column name.
    cols= _df.shape[1]
    for col in range(7, cols, 2):
        ## Extract the party acronym from the first non-null entry.
        try:
            party_acronym = _df.iloc[:, col].dropna().iloc[0]
        except IndexError:
            ## If the column is empty, use a generic name.
            party_acronym = f"party{col}"
        mapping[col] = party_acronym
        if col + 1 < cols:
            mapping[col + 1] = f"{party_acronym}_votes"
        
    return mapping

